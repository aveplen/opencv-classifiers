# opencv-classifiers

Датасеты:
- grocery-store https://github.com/marcusklasson/GroceryStoreDataset
- cifar-10 https://www.cs.toronto.edu/~kriz/cifar.html
- tiny-imagenet https://huggingface.co/datasets/zh-plus/tiny-imagenet

### TODO:

#### Обучить knn, svn, rf, alexnet на небольшом датасете

**Смысл:**
На просторах интернета практически невозможно найти пред-обученные svn, knn и/или rf-классификаторы на каком-либо популярном датасете. Также практически невозможно найти большие cnn-модели, обученные на маленьких датасетах. Таким образом невозможно привести эти "алгоритмы" к одинаковым условиям, чтобы сравнить их результаты. Чтобы всё таки привести какое-то сравнение, обучаем простые модели и cnn на достаточно небольшом датасете, работа с которым не займет чрезвычайно большого кол-ва времени и ресурсов и при этом сможет дать результаты для относительного сравнения подходов. 

**Цель:**
Отбросить классические алгоритмы из дальнейшего сравнения по какой-либо причине.

**Доработки по бэкенду:**

- [ ] Обучить svn-классификатор на grocery-store
- [ ] Написать отдельные main'ы для тестирования классификаторов
- [ ] Обучить knn-классификатор на grocery-store
- [ ] Обучить rf-классификатор на grocery-store
- [ ] Перенести веса классических классификаторов из scikit-learn формата в opencv
- [ ] Обучить alexnet на grocery-store
- [ ] Перевести alexnet в onnx
- [ ] Добавить поддержку наборов моделей, aka. престов (конфиг + контроллер + история)
- [ ] Добавить пресет с классическими моделями

**Доработки по фронтенду:**

- [ ] Добавить на страницу классификации выбор пресета, описание пресета

**Записки:**

Примеры кода обучения knn, svn, rf:
https://github.com/snatch59/cnn-svm-classifier/blob/master/inceptionv3_svm_classifier.py#L211

Статья про конвертацию pytorch-моделей в onnx:
https://deci.ai/blog/how-to-convert-a-pytorch-model-to-onnx/

Обучение alexnet на pytorch:
https://youtu.be/6c8WFGbPHpE

---

#### Обучить knn, svn, rf на базе resnet50 на небольшом датасете

**Смысл:**
Обучать svn, knn и rf на базе своего датасета это очень дорого из-за того, что весь датасет + огромные матрицы, возникающие в процессе обучения, требуют очень много памяти. Поэтому картинки приходится скейлить, что приводит к ухудшению результатов итоговой модели и последующей классификации. Решаем эту проблему, используя готовую гигантскую нейронную сеть для построения векторов фич, которые в последствии скармливаются классическим классификаторам вместо изображений.

**Цель:**
Отбросить классические алгоритмы из дальнейшего сравнения по какой-либо причине.

**Доработки по бэкенду:**

- [ ] Обучить knn-классификатор поверх resnet50 на grocery-store
- [ ] Обучить svn-классификатор поверх resnet50 на grocery-store
- [ ] Обучить rf-классификатор поверх resnet50 на grocery-store
- [ ] Сконвертировать классические классификаторы в монолитную модель и формат onnx
- [ ] Зафитить resnet50 на grocery-store, вывести в onnx
- [ ] Добавить пресет с классическими моделями поверх resnet50

**Доработки по фронтенду:**

- нет

**Записки:**

Тут целый репозиторий с transfer-learning'ом:
https://github.com/snatch59/cnn-svm-classifier/tree/master

Видео с примерами transfer-learning'a:
https://youtu.be/vbhEnEbj3JM

Тутор на медиуме:
https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b

Тутор на tensoflow:
https://www.tensorflow.org/tutorials/images/transfer_learning

Что такое transfer-learning и fine-tuning (тут статья про конкретный кейс, но есть общее описание):
https://bmcmedimaging.biomedcentral.com/articles/10.1186/s12880-022-00793-7
