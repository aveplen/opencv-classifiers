{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img):\n",
    "  width, height = img.shape[1], img.shape[0]\n",
    "  crop_width = min(img.shape[0], img.shape[1])\n",
    "  crop_height = min(img.shape[0], img.shape[1])\n",
    "  mid_x, mid_y = int(width/2), int(height/2)\n",
    "  cw2, ch2 = int(crop_width/2), int(crop_height/2) \n",
    "  crop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n",
    "  return crop_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, dimensions, svm_name, kmeans_name = (\n",
    "#   \"groceries\", \n",
    "#   (224, 224), \n",
    "#   \"models/sift_kmeans_svm_groceries.dat\",\n",
    "#   \"models/sift_kmeans_svm_groceries_centers.npy\"\n",
    "# )\n",
    "\n",
    "# dataset, dimensions, svm_name, kmeans_name = (\n",
    "#   \"cifar-10\", \n",
    "#   (64, 64),\n",
    "#   \"models/sift_kmeans_svm_cifar.dat\",\n",
    "#   \"models/sift_kmeans_svm_cifar_centers.npy\"\n",
    "# )\n",
    "\n",
    "dataset, dimensions, svm_name, kmeans_name = (\n",
    "  \"caltech-256\", \n",
    "  (224, 224),\n",
    "  \"models/sift_kmeans_svm_caltech.dat\",\n",
    "  \"models/sift_kmeans_svm_caltech_centers.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "def load_image_files(images_dir_path, test_size=0.2, target_size=(224, 224),):\n",
    "    images_dir = Path(images_dir_path)\n",
    "    directories = [directory for directory in images_dir.iterdir()]\n",
    "    classes = [class_directory.name.lower() for class_directory in directories]\n",
    "\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    for class_index, directory in enumerate(directories):\n",
    "        class_images_cnt = 0\n",
    "        for file in directory.iterdir():\n",
    "            class_images_cnt += 1\n",
    "\n",
    "        sift = cv2.SIFT_create()\n",
    "        test_size_cnt = int(class_images_cnt * test_size)\n",
    "        for i, file in enumerate(directory.iterdir()):\n",
    "            image = cv2.imread(file.as_posix(), cv2.IMREAD_COLOR)\n",
    "            if image is None:\n",
    "                print(\"bad file: \", file.as_posix())\n",
    "                continue\n",
    "\n",
    "            width, height = image.shape[1], image.shape[0]\n",
    "            if width == 0 or height == 0:\n",
    "                print(\"bad file: \", file.as_posix())\n",
    "                continue\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = crop_center(image)\n",
    "            image = cv2.resize(image, target_size)\n",
    "            kp, des = sift.detectAndCompute(image, None)\n",
    "\n",
    "            batch = Bunch(\n",
    "                # image=image,\n",
    "                class_index=class_index,\n",
    "                class_name=classes[class_index],\n",
    "                des = des,\n",
    "                kp = kp,\n",
    "            )\n",
    "\n",
    "            if i < test_size_cnt:\n",
    "                test_data.append(batch)\n",
    "                continue\n",
    "\n",
    "            train_data.append(batch)\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = load_image_files(dataset, target_size=dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render sample train image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# random_index = np.random.randint(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_dataset[random_index].image.astype(int))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train and test data from batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# descriptors_stack = np.vstack([batch.des for batch in train_dataset])\n",
    "descriptors = []\n",
    "for batch in train_dataset:\n",
    "    if batch.des is not None:\n",
    "        descriptors.append(batch.des)\n",
    "\n",
    "train_dataset = None\n",
    "descriptors_stack = np.vstack(descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 200\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.01)\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "_, cluster_ids, cluster_centers = cv2.kmeans(descriptors_stack, num_clusters, None, criteria, 10, flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate histograms for each image in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "1%\n",
      "2%\n",
      "3%\n",
      "4%\n",
      "5%\n",
      "6%\n",
      "7%\n",
      "8%\n",
      "9%\n",
      "10%\n",
      "11%\n",
      "12%\n",
      "13%\n",
      "14%\n",
      "15%\n",
      "16%\n",
      "17%\n",
      "18%\n",
      "19%\n",
      "20%\n",
      "21%\n",
      "22%\n",
      "23%\n",
      "24%\n",
      "25%\n",
      "26%\n",
      "27%\n",
      "28%\n",
      "29%\n",
      "30%\n",
      "31%\n",
      "32%\n",
      "33%\n",
      "34%\n",
      "35%\n",
      "36%\n",
      "37%\n",
      "38%\n",
      "39%\n",
      "40%\n",
      "41%\n",
      "42%\n",
      "43%\n",
      "44%\n",
      "45%\n",
      "46%\n",
      "47%\n",
      "48%\n",
      "49%\n",
      "50%\n",
      "51%\n",
      "52%\n",
      "53%\n",
      "54%\n",
      "55%\n",
      "56%\n",
      "57%\n",
      "58%\n",
      "59%\n",
      "60%\n",
      "61%\n",
      "62%\n",
      "63%\n",
      "64%\n",
      "65%\n",
      "66%\n",
      "67%\n",
      "68%\n",
      "69%\n",
      "70%\n",
      "71%\n",
      "72%\n",
      "73%\n",
      "74%\n",
      "75%\n",
      "76%\n",
      "77%\n",
      "78%\n",
      "79%\n",
      "80%\n",
      "81%\n",
      "82%\n",
      "83%\n",
      "84%\n",
      "85%\n",
      "86%\n",
      "87%\n",
      "88%\n",
      "89%\n",
      "90%\n",
      "91%\n",
      "92%\n",
      "93%\n",
      "94%\n",
      "95%\n",
      "96%\n",
      "97%\n",
      "98%\n",
      "99%\n"
     ]
    }
   ],
   "source": [
    "def calculate_histogram(cluster_centers, image_descriptor):\n",
    "  histogram = np.zeros(len(cluster_centers))\n",
    "  for descriptor in image_descriptor:\n",
    "      distances = np.linalg.norm(descriptor - cluster_centers, axis=1)\n",
    "      nearest_cluster_index = np.argmin(distances)\n",
    "      histogram[nearest_cluster_index] += 1\n",
    "  return histogram\n",
    "\n",
    "\n",
    "def calc_histograms_progress(dataset, cluster_centers):\n",
    "  histograms = []\n",
    "  last_percent = -1\n",
    "  for i in range(len(dataset)):\n",
    "    histograms.append(calculate_histogram(cluster_centers, dataset[i].des))\n",
    "\n",
    "    percent_candidate = int((i / len(dataset)) * 100)\n",
    "    if percent_candidate > last_percent:\n",
    "      print(f\"{percent_candidate}%\")\n",
    "      last_percent = percent_candidate\n",
    "\n",
    "  return np.asarray(histograms)\n",
    "\n",
    "\n",
    "x_train = calc_histograms_progress(train_dataset, cluster_centers)\n",
    "y_train = np.asarray([batch.class_index for batch in train_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn SVM on features extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "svm.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, 500, 1e-6))\n",
    "svm.train(x_train.astype(np.float32), cv2.ml.ROW_SAMPLE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "1%\n",
      "2%\n",
      "3%\n",
      "4%\n",
      "5%\n",
      "6%\n",
      "7%\n",
      "8%\n",
      "9%\n",
      "10%\n",
      "11%\n",
      "12%\n",
      "13%\n",
      "14%\n",
      "15%\n",
      "16%\n",
      "17%\n",
      "18%\n",
      "19%\n",
      "20%\n",
      "21%\n",
      "22%\n",
      "23%\n",
      "24%\n",
      "25%\n",
      "26%\n",
      "27%\n",
      "28%\n",
      "29%\n",
      "30%\n",
      "31%\n",
      "32%\n",
      "33%\n",
      "34%\n",
      "35%\n",
      "36%\n",
      "37%\n",
      "38%\n",
      "39%\n",
      "40%\n",
      "41%\n",
      "42%\n",
      "43%\n",
      "44%\n",
      "45%\n",
      "46%\n",
      "47%\n",
      "48%\n",
      "49%\n",
      "50%\n",
      "51%\n",
      "52%\n",
      "53%\n",
      "54%\n",
      "55%\n",
      "56%\n",
      "57%\n",
      "58%\n",
      "59%\n",
      "60%\n",
      "61%\n",
      "62%\n",
      "63%\n",
      "64%\n",
      "65%\n",
      "66%\n",
      "67%\n",
      "68%\n",
      "69%\n",
      "70%\n",
      "71%\n",
      "72%\n",
      "73%\n",
      "74%\n",
      "75%\n",
      "76%\n",
      "77%\n",
      "78%\n",
      "79%\n",
      "80%\n",
      "81%\n",
      "82%\n",
      "83%\n",
      "84%\n",
      "85%\n",
      "86%\n",
      "87%\n",
      "88%\n",
      "89%\n",
      "90%\n",
      "91%\n",
      "92%\n",
      "93%\n",
      "94%\n",
      "95%\n",
      "96%\n",
      "97%\n",
      "98%\n",
      "99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.09      0.09        33\n",
      "           1       0.24      0.27      0.25        52\n",
      "           2       0.22      0.27      0.24        37\n",
      "           3       0.15      0.19      0.17        31\n",
      "           4       0.30      0.27      0.28        30\n",
      "           5       0.23      0.37      0.28        19\n",
      "           6       0.33      0.34      0.34        32\n",
      "           7       0.16      0.15      0.16        59\n",
      "           8       0.20      0.27      0.23        22\n",
      "           9       0.15      0.12      0.13        60\n",
      "          10       0.26      0.38      0.31        21\n",
      "          11       0.26      0.29      0.27        55\n",
      "          12       0.34      0.40      0.37        35\n",
      "          13       0.16      0.18      0.17        34\n",
      "          14       0.13      0.12      0.13        56\n",
      "          15       0.20      0.19      0.19        32\n",
      "          16       0.29      0.25      0.27        28\n",
      "          17       0.18      0.16      0.17        61\n",
      "          18       0.43      0.35      0.39        74\n",
      "          19       0.44      0.48      0.46        23\n",
      "          20       0.39      0.27      0.32        41\n",
      "          21       0.22      0.30      0.25        27\n",
      "          22       0.32      0.25      0.28        48\n",
      "          23       0.43      0.35      0.39        34\n",
      "          24       0.36      0.28      0.31        36\n",
      "\n",
      "    accuracy                           0.25       980\n",
      "   macro avg       0.26      0.26      0.26       980\n",
      "weighted avg       0.26      0.25      0.25       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_test = calc_histograms_progress(test_dataset, cluster_centers)\n",
    "y_test = np.asarray([batch.class_index for batch in test_dataset])\n",
    "\n",
    "_, y_pred = svm.predict(x_test.astype(np.float32))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.save(svm_name)\n",
    "np.save(kmeans_name, cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "1%\n",
      "2%\n",
      "3%\n",
      "4%\n",
      "5%\n",
      "6%\n",
      "7%\n",
      "8%\n",
      "9%\n",
      "10%\n",
      "11%\n",
      "12%\n",
      "13%\n",
      "14%\n",
      "15%\n",
      "16%\n",
      "17%\n",
      "18%\n",
      "19%\n",
      "20%\n",
      "21%\n",
      "22%\n",
      "23%\n",
      "24%\n",
      "25%\n",
      "26%\n",
      "27%\n",
      "28%\n",
      "29%\n",
      "30%\n",
      "31%\n",
      "32%\n",
      "33%\n",
      "34%\n",
      "35%\n",
      "36%\n",
      "37%\n",
      "38%\n",
      "39%\n",
      "40%\n",
      "41%\n",
      "42%\n",
      "43%\n",
      "44%\n",
      "45%\n",
      "46%\n",
      "47%\n",
      "48%\n",
      "49%\n",
      "50%\n",
      "51%\n",
      "52%\n",
      "53%\n",
      "54%\n",
      "55%\n",
      "56%\n",
      "57%\n",
      "58%\n",
      "59%\n",
      "60%\n",
      "61%\n",
      "62%\n",
      "63%\n",
      "64%\n",
      "65%\n",
      "66%\n",
      "67%\n",
      "68%\n",
      "69%\n",
      "70%\n",
      "71%\n",
      "72%\n",
      "73%\n",
      "74%\n",
      "75%\n",
      "76%\n",
      "77%\n",
      "78%\n",
      "79%\n",
      "80%\n",
      "81%\n",
      "82%\n",
      "83%\n",
      "84%\n",
      "85%\n",
      "86%\n",
      "87%\n",
      "88%\n",
      "89%\n",
      "90%\n",
      "91%\n",
      "92%\n",
      "93%\n",
      "94%\n",
      "95%\n",
      "96%\n",
      "97%\n",
      "98%\n",
      "99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.09      0.09        33\n",
      "           1       0.24      0.27      0.25        52\n",
      "           2       0.22      0.27      0.24        37\n",
      "           3       0.15      0.19      0.17        31\n",
      "           4       0.30      0.27      0.28        30\n",
      "           5       0.23      0.37      0.28        19\n",
      "           6       0.33      0.34      0.34        32\n",
      "           7       0.16      0.15      0.16        59\n",
      "           8       0.20      0.27      0.23        22\n",
      "           9       0.15      0.12      0.13        60\n",
      "          10       0.26      0.38      0.31        21\n",
      "          11       0.26      0.29      0.27        55\n",
      "          12       0.34      0.40      0.37        35\n",
      "          13       0.16      0.18      0.17        34\n",
      "          14       0.13      0.12      0.13        56\n",
      "          15       0.20      0.19      0.19        32\n",
      "          16       0.29      0.25      0.27        28\n",
      "          17       0.18      0.16      0.17        61\n",
      "          18       0.43      0.35      0.39        74\n",
      "          19       0.44      0.48      0.46        23\n",
      "          20       0.39      0.27      0.32        41\n",
      "          21       0.22      0.30      0.25        27\n",
      "          22       0.32      0.25      0.28        48\n",
      "          23       0.43      0.35      0.39        34\n",
      "          24       0.36      0.28      0.31        36\n",
      "\n",
      "    accuracy                           0.25       980\n",
      "   macro avg       0.26      0.26      0.26       980\n",
      "weighted avg       0.26      0.25      0.25       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = cv2.ml.SVM_load(svm_name)\n",
    "cluster_centers = np.load(kmeans_name)\n",
    "\n",
    "x_test = calc_histograms_progress(test_dataset, cluster_centers)\n",
    "y_test = np.asarray([batch.class_index for batch in test_dataset])\n",
    "_, y_pred = svm.predict(x_test.astype(np.float32))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
